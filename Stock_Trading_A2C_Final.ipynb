{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Library import & Drive mount"
      ],
      "metadata": {
        "id": "3lGJ1SdFUjyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-asTv-eoTkVT",
        "outputId": "6c05f31b-20d0-4a12-a074-0bc50310b401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Reinforcement_Learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIe3lzcZTqRA",
        "outputId": "bccab49e-a3aa-4afd-a98b-0f11d45f5348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Reinforcement_Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IRpZhCX8LTF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils import weight_norm\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from collections import deque\n",
        "import torch.optim as optim\n",
        "import importlib\n",
        "from calculate_tech_ind import calculate_macd, calculate_rsi, calculate_cci, calculate_adx\n",
        "from model import PreLSTM, PolicyNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl_zdekM2AjR",
        "outputId": "5bb8de82-2440-4ef3-ca56-75e101be9cc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "set_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data download and Preprocessing"
      ],
      "metadata": {
        "id": "f3Upl-IAT4Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "symbols = {\n",
        "    'S&P 500': '^GSPC',\n",
        "    'Dow Jones': '^DJI',\n",
        "    'KOSPI': '^KS11'\n",
        "}\n",
        "start_date = '2012-12-01'\n",
        "end_date = '2023-12-31'\n",
        "\n",
        "market_data = {}\n",
        "for name, ticker in symbols.items():\n",
        "    data = yf.download(ticker, start=start_date, end=end_date)\n",
        "    market_data[name] = data\n",
        "\n",
        "snp500_data = market_data['S&P 500']\n",
        "dowjones_data = market_data['Dow Jones']\n",
        "kospi_data = market_data['KOSPI']\n",
        "#print(snp500_data)\n",
        "\n",
        "# 공통 거래일 계산\n",
        "common_dates = snp500_data.index.intersection(dowjones_data.index).intersection(kospi_data.index)\n",
        "\n",
        "# 공통 거래일 기준 데이터 정렬\n",
        "snp500_data_aligned = snp500_data.loc[common_dates]\n",
        "dowjones_data_aligned = dowjones_data.loc[common_dates]\n",
        "kospi_data_aligned = kospi_data.loc[common_dates]\n",
        "\n",
        "snp500_data_aligned = calculate_macd(snp500_data_aligned)\n",
        "snp500_data_aligned = calculate_rsi(snp500_data_aligned)\n",
        "snp500_data_aligned = calculate_cci(snp500_data_aligned)\n",
        "\n",
        "dowjones_data_aligned = calculate_macd(dowjones_data_aligned)\n",
        "dowjones_data_aligned = calculate_rsi(dowjones_data_aligned)\n",
        "dowjones_data_aligned = calculate_cci(dowjones_data_aligned)\n",
        "\n",
        "kospi_data_aligned = calculate_macd(kospi_data_aligned)\n",
        "kospi_data_aligned = calculate_rsi(kospi_data_aligned)\n",
        "kospi_data_aligned = calculate_cci(kospi_data_aligned)\n",
        "\n",
        "# Close, MACD, RSI 병합\n",
        "merged_close = pd.concat([\n",
        "    snp500_data_aligned[['Close']].rename(columns={'Close': 'S&P 500 Close'}),\n",
        "    dowjones_data_aligned[['Close']].rename(columns={'Close': 'Dow Jones Close'}),\n",
        "    kospi_data_aligned[['Close']].rename(columns={'Close': 'KOSPI Close'})\n",
        "], axis=1)\n",
        "\n",
        "merged_macd = pd.concat([\n",
        "    snp500_data_aligned[['MACD']].rename(columns={'MACD': 'S&P 500 MACD'}),\n",
        "    dowjones_data_aligned[['MACD']].rename(columns={'MACD': 'Dow Jones MACD'}),\n",
        "    kospi_data_aligned[['MACD']].rename(columns={'MACD': 'KOSPI MACD'})\n",
        "], axis=1)\n",
        "\n",
        "merged_rsi = pd.concat([\n",
        "    snp500_data_aligned[['RSI']].rename(columns={'RSI': 'S&P 500 RSI'}),\n",
        "    dowjones_data_aligned[['RSI']].rename(columns={'RSI': 'Dow Jones RSI'}),\n",
        "    kospi_data_aligned[['RSI']].rename(columns={'RSI': 'KOSPI RSI'})\n",
        "], axis=1)\n",
        "\n",
        "merged_cci = pd.concat([\n",
        "    snp500_data_aligned[['CCI']].rename(columns={'CCI': 'S&P 500 CCI'}),\n",
        "    dowjones_data_aligned[['CCI']].rename(columns={'CCI': 'Dow Jones CCI'}),\n",
        "    kospi_data_aligned[['CCI']].rename(columns={'CCI': 'KOSPI CCI'})\n",
        "], axis=1)\n",
        "\n",
        "# 전체 병합 데이터 생성\n",
        "merged_data_all = pd.concat([merged_close, merged_macd, merged_rsi, merged_cci], axis=1)\n",
        "\n",
        "# 날짜 기준 필터링\n",
        "merged_data_all = merged_data_all[merged_data_all.index > '2013-02-01']\n",
        "\n",
        "print(merged_data_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gdLNLmDfg6dl",
        "outputId": "960d455c-25f3-4ed7-ab37-bf6ce6eca7e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price      S&P 500 Close Dow Jones Close  KOSPI Close S&P 500 MACD  \\\n",
            "Ticker             ^GSPC            ^DJI        ^KS11                \n",
            "Date                                                                 \n",
            "2013-02-04   1495.709961    13880.080078  1953.209961    16.833122   \n",
            "2013-02-05   1511.290039    13979.299805  1938.180054    16.887413   \n",
            "2013-02-06   1512.119995    13986.519531  1936.189941    16.803706   \n",
            "2013-02-07   1509.390015    13944.049805  1931.770020    16.328852   \n",
            "2013-02-08   1517.930054    13992.969727  1950.900024    16.451989   \n",
            "...                  ...             ...          ...          ...   \n",
            "2023-12-21   4746.750000    37404.351562  2600.020020    76.724339   \n",
            "2023-12-22   4754.629883    37385.968750  2599.510010    76.666913   \n",
            "2023-12-26   4774.750000    37545.328125  2602.590088    77.353248   \n",
            "2023-12-27   4781.580078    37656.519531  2613.500000    77.554305   \n",
            "2023-12-28   4783.350098    37710.101562  2655.280029    76.969218   \n",
            "\n",
            "Price      Dow Jones MACD KOSPI MACD S&P 500 RSI Dow Jones RSI  KOSPI RSI  \\\n",
            "Ticker                                                                      \n",
            "Date                                                                        \n",
            "2013-02-04     180.360074  -7.470035   64.728699     70.818071  31.785890   \n",
            "2013-02-05     180.065726  -9.053764   69.693633     72.980479  33.670288   \n",
            "2013-02-06     178.359013 -10.350155   69.858200     75.002312  34.741143   \n",
            "2013-02-07     171.601365 -11.600483   65.157209     69.161056  34.425410   \n",
            "2013-02-08     168.253785 -10.921844   66.409903     68.998543  36.988559   \n",
            "...                   ...        ...         ...           ...        ...   \n",
            "2023-12-21     700.546982  33.386099   69.835202     73.243639  71.519845   \n",
            "2023-12-22     687.566322  34.442140   75.219000     73.916007  70.007602   \n",
            "2023-12-26     682.273204  35.122724   77.026599     77.862195  77.953871   \n",
            "2023-12-27     679.220951  36.125993   81.131399     80.920028  79.016433   \n",
            "2023-12-28     673.363525  39.833217   79.209536     80.850790  83.719638   \n",
            "\n",
            "Price      S&P 500 CCI Dow Jones CCI   KOSPI CCI  \n",
            "Ticker                                            \n",
            "Date                                              \n",
            "2013-02-04   73.746353     84.625677  -71.733645  \n",
            "2013-02-05   91.400688     88.549134 -131.124200  \n",
            "2013-02-06   95.746782     83.338664 -111.608750  \n",
            "2013-02-07   76.991980     65.449148 -107.568728  \n",
            "2013-02-08  112.431485     82.164587  -71.018357  \n",
            "...                ...           ...         ...  \n",
            "2023-12-21  103.481750    100.841129  174.089461  \n",
            "2023-12-22  106.663068     97.038802  158.674305  \n",
            "2023-12-26  107.646047     97.460350  128.034459  \n",
            "2023-12-27  100.772878     97.615953  114.320801  \n",
            "2023-12-28   97.092625    100.516152  151.994028  \n",
            "\n",
            "[2597 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment"
      ],
      "metadata": {
        "id": "F-vGveYJUFuF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpJRQCMswFJu"
      },
      "outputs": [],
      "source": [
        "class env():\n",
        "  def __init__(self, data:pd.DataFrame, train_split_date = '2021-01-01', valid_split_date = '2022-01-01', test_split_date  = '2023-01-01'):\n",
        "    self.data = data\n",
        "    self.t = 0\n",
        "    self.train_data = torch.tensor(self.data[self.data.index < train_split_date].values).to(torch.float32).to(device)\n",
        "    self.valid_data = torch.tensor(self.data[(self.data.index >= train_split_date) & (self.data.index < valid_split_date)].values).to(torch.float32).to(device)\n",
        "    self.test_data = torch.tensor(self.data[self.data.index >= test_split_date].values).to(torch.float32).to(device)\n",
        "    #self.max_shares = 100\n",
        "\n",
        "  def step(self, state, action, data): #데이터 앞의 세개는 각 인덱스의 가격으로 설정\n",
        "      shares_to_buy = torch.round(action).to(torch.float32).to(device)\n",
        "      num_stock, balance = state[-4:-1], state[-1]\n",
        "      W = torch.dot(state[:3], num_stock) + balance\n",
        "      #print(shares_to_buy.device, num_stock.device, balance.device)\n",
        "      shares_to_buy = torch.where(shares_to_buy + num_stock < 0, -num_stock, shares_to_buy)\n",
        "      cost = torch.dot(data[self.t,:3], shares_to_buy)\n",
        "\n",
        "      #print(f\"shares_to_buy: {shares_to_buy}, balance: {balance}, cost: {cost}\")\n",
        "      if cost > balance:\n",
        "          cost = torch.tensor(0).to(device)\n",
        "          shares_to_buy = torch.zeros(3).to(device)\n",
        "      n_balance = balance - cost\n",
        "      self.t += 1\n",
        "\n",
        "      done = self.t >= (data.shape[0] - 1)\n",
        "\n",
        "      n_num_stock = num_stock + shares_to_buy\n",
        "      n_W = torch.dot(data[self.t,:3], n_num_stock) + n_balance\n",
        "\n",
        "      n_state = torch.hstack((data[self.t, :], n_num_stock, n_balance))\n",
        "      reward = n_W - W\n",
        "\n",
        "      #print(f\"n_balance: {n_balance}, n_stock: {n_num_stock}, n_W: {n_W}, reward: {reward}\")\n",
        "      return n_state, reward, done\n",
        "\n",
        "  def train_step(self, state, action):\n",
        "      return self.step(state, action, self.train_data)\n",
        "\n",
        "  def test_step(self, state, action):\n",
        "      return self.step(state, action, self.test_data)\n",
        "\n",
        "  def valid_step(self, state, action):\n",
        "      return self.step(state, action, self.valid_data)\n",
        "\n",
        "  def reset(self, data):\n",
        "      self.t = 0\n",
        "      init_S = torch.zeros(3).to(device)\n",
        "      init_B = torch.tensor(1e8).to(device)\n",
        "      init_state = torch.hstack((data[0,:], init_S, init_B))\n",
        "      return init_state\n",
        "\n",
        "  def train_reset(self):\n",
        "      return self.reset(self.train_data)\n",
        "\n",
        "  def test_reset(self):\n",
        "      return self.reset(self.test_data)\n",
        "\n",
        "  def valid_reset(self):\n",
        "      return self.reset(self.valid_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A2C Agent"
      ],
      "metadata": {
        "id": "ggI5SIURUKdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "from collections import deque\n",
        "import model\n",
        "import importlib\n",
        "importlib.reload(model)\n",
        "\n",
        "GAMMA = 0.99\n",
        "LEARNING_RATE = 0.0001\n",
        "REPLAY_MEMORY_SIZE = 5000\n",
        "MIN_REPLAY_MEMORY_SIZE = 1000\n",
        "BATCH_SIZE = 128\n",
        "TAU = 0.1\n",
        "K = 100\n",
        "\n",
        "class A2CAgent:\n",
        "    def __init__(self, window_size, num_stocks, feature_len, n_channels, k):\n",
        "        self.num_stocks = num_stocks\n",
        "        self.feature_extractor = model.PreLSTM(n_channels, hidden_dim=128, output_dim=feature_len).to(device)\n",
        "        self.policy_network = model.PolicyNetwork(self.feature_extractor, num_stocks).to(device)\n",
        "        self.value_network = model.ValueNetwork(self.feature_extractor).to(device)\n",
        "\n",
        "        self.policy_optimizer = optim.Adam(list(self.feature_extractor.parameters()) + list(self.policy_network.parameters()), lr=LEARNING_RATE)\n",
        "        self.value_optimizer = optim.Adam(self.value_network.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
        "        self.gamma = GAMMA\n",
        "        self.state_buffer = deque(maxlen=window_size)\n",
        "        self.k = k\n",
        "\n",
        "    def act(self, state):\n",
        "        self.state_buffer.append(state)\n",
        "        if len(self.state_buffer) < self.state_buffer.maxlen:\n",
        "            return torch.zeros(self.num_stocks).to(device)\n",
        "\n",
        "        state = torch.stack(list(self.state_buffer)).to(torch.float32).to(device)\n",
        "\n",
        "        # action sampling\n",
        "        with torch.no_grad():\n",
        "            mu, sigma_diag = self.policy_network(state)  # size: (6,)\n",
        "            sigma = torch.diag(torch.clamp(sigma_diag, min=1e-6))\n",
        "\n",
        "            # use Multivariate Normal Distribution\n",
        "            action_dist = torch.distributions.MultivariateNormal(mu, covariance_matrix=sigma)\n",
        "            sampled_action = action_dist.sample()\n",
        "            clipped_action = torch.clamp(sampled_action, -1, 1)  # Clipping [-1, 1]\n",
        "            discrete_action = (clipped_action * self.k).long()  # from continuous [-1,1]^3 to discrete {-k, .. ,0, .. k}^3\n",
        "\n",
        "        return discrete_action.cpu()\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.replay_memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def replay(self):\n",
        "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
        "            return\n",
        "\n",
        "        minibatch = random.sample(self.replay_memory, BATCH_SIZE)\n",
        "        states, actions, rewards, next_states, dones = zip(*minibatch)\n",
        "\n",
        "        states = torch.stack(states).to(torch.float32).to(device)\n",
        "        actions = torch.stack(actions).to(torch.float32).to(device)\n",
        "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
        "        next_states = torch.stack(next_states).to(torch.float32).to(device)\n",
        "        dones = torch.tensor(dones, dtype=torch.float32).to(device)\n",
        "\n",
        "        # Calculate Advantage\n",
        "        with torch.no_grad():\n",
        "            next_values = self.value_network(next_states).squeeze()  # (BATCH_SIZE,)\n",
        "            targets = rewards + (1 - dones) * self.gamma * next_values\n",
        "            advantages = targets - self.value_network(states).squeeze()\n",
        "\n",
        "        mu, sigma_diag = self.policy_network(states)\n",
        "        #print(mu.shape, sigma_diag.shape)\n",
        "        sigma = torch.stack([torch.diag(torch.clamp(s, min=1e-6)) for s in sigma_diag])\n",
        "\n",
        "        action_dist = torch.distributions.MultivariateNormal(mu, covariance_matrix=sigma)\n",
        "        log_probs = action_dist.log_prob(actions)\n",
        "        policy_loss = -(log_probs * advantages).mean()\n",
        "\n",
        "        # Value Loss\n",
        "        value_loss = nn.MSELoss()(self.value_network(states).squeeze(), targets)\n",
        "\n",
        "        # Total Loss\n",
        "        total_loss = policy_loss + 0.5 * value_loss\n",
        "\n",
        "        self.policy_optimizer.zero_grad()\n",
        "        self.value_optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        self.policy_optimizer.step()\n",
        "        self.value_optimizer.step()\n"
      ],
      "metadata": {
        "id": "EDFuNFspwUJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A2C Train"
      ],
      "metadata": {
        "id": "KLf36qREUbPk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOqM9fRSBKWe",
        "outputId": "6e03a9f3-42bc-4355-86ef-a9061f47155f",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1, Total Reward: 13361544.0\n",
            "validation_reward: 2024224.0\n",
            "Episode: 2, Total Reward: 20652144.0\n",
            "Episode: 3, Total Reward: 22521392.0\n",
            "Episode: 4, Total Reward: 28536272.0\n",
            "Episode: 5, Total Reward: 50416104.0\n",
            "Episode: 6, Total Reward: 24773080.0\n",
            "validation_reward: 4356240.0\n",
            "Episode: 7, Total Reward: 27925904.0\n",
            "Episode: 8, Total Reward: 34905624.0\n",
            "Episode: 9, Total Reward: 31565440.0\n",
            "Episode: 10, Total Reward: 33008776.0\n",
            "Episode: 11, Total Reward: 27200072.0\n",
            "validation_reward: 1882760.0\n",
            "Episode: 12, Total Reward: 32660880.0\n",
            "Episode: 13, Total Reward: 42158608.0\n",
            "Episode: 14, Total Reward: 21295640.0\n",
            "Episode: 15, Total Reward: 27897720.0\n",
            "Episode: 16, Total Reward: 31777408.0\n",
            "validation_reward: 5701712.0\n",
            "Episode: 17, Total Reward: 34404560.0\n",
            "Episode: 18, Total Reward: 33697024.0\n",
            "Episode: 19, Total Reward: 35055896.0\n",
            "Episode: 20, Total Reward: 39135984.0\n",
            "Episode: 21, Total Reward: 32735960.0\n",
            "validation_reward: 2510464.0\n",
            "Episode: 22, Total Reward: 28244680.0\n",
            "Episode: 23, Total Reward: 33924840.0\n",
            "Episode: 24, Total Reward: 55077744.0\n",
            "Episode: 25, Total Reward: 39711496.0\n",
            "Episode: 26, Total Reward: 44339936.0\n",
            "validation_reward: 6874776.0\n",
            "Episode: 27, Total Reward: 52035720.0\n",
            "Episode: 28, Total Reward: 49485768.0\n",
            "Episode: 29, Total Reward: 62791624.0\n",
            "Episode: 30, Total Reward: 69015816.0\n",
            "Episode: 31, Total Reward: 67282936.0\n",
            "validation_reward: 4569112.0\n",
            "Episode: 32, Total Reward: 62745000.0\n",
            "Episode: 33, Total Reward: 56906000.0\n",
            "Episode: 34, Total Reward: 64717360.0\n",
            "Episode: 35, Total Reward: 56432440.0\n",
            "Episode: 36, Total Reward: 53535464.0\n",
            "validation_reward: 6474280.0\n",
            "Episode: 37, Total Reward: 56267168.0\n",
            "Episode: 38, Total Reward: 59047024.0\n",
            "Episode: 39, Total Reward: 64189936.0\n",
            "Episode: 40, Total Reward: 62929512.0\n",
            "Episode: 41, Total Reward: 65770304.0\n",
            "validation_reward: 8686520.0\n",
            "Episode: 42, Total Reward: 62954552.0\n",
            "Episode: 43, Total Reward: 63202616.0\n",
            "Episode: 44, Total Reward: 65884056.0\n",
            "Episode: 45, Total Reward: 63555480.0\n",
            "Episode: 46, Total Reward: 59816040.0\n",
            "validation_reward: 4523912.0\n",
            "Episode: 47, Total Reward: 62396760.0\n",
            "Episode: 48, Total Reward: 60206424.0\n",
            "Episode: 49, Total Reward: 62622200.0\n",
            "Episode: 50, Total Reward: 62397368.0\n",
            "Episode: 51, Total Reward: 63417168.0\n",
            "validation_reward: 4008656.0\n",
            "Episode: 52, Total Reward: 67104720.0\n",
            "Episode: 53, Total Reward: 67457096.0\n",
            "Episode: 54, Total Reward: 64052864.0\n",
            "Episode: 55, Total Reward: 67072360.0\n",
            "Episode: 56, Total Reward: 70902544.0\n",
            "validation_reward: 3204768.0\n",
            "Episode: 57, Total Reward: 68824560.0\n",
            "Episode: 58, Total Reward: 69689008.0\n",
            "Episode: 59, Total Reward: 72366272.0\n",
            "Episode: 60, Total Reward: 67035536.0\n",
            "Episode: 61, Total Reward: 78251752.0\n",
            "validation_reward: 9296304.0\n",
            "Episode: 62, Total Reward: 76024120.0\n",
            "Episode: 63, Total Reward: 80235152.0\n",
            "Episode: 64, Total Reward: 74393080.0\n",
            "Episode: 65, Total Reward: 72363928.0\n",
            "Episode: 66, Total Reward: 70907016.0\n",
            "validation_reward: 10576824.0\n",
            "Episode: 67, Total Reward: 65588064.0\n",
            "Episode: 68, Total Reward: 72510744.0\n",
            "Episode: 69, Total Reward: 71326944.0\n",
            "Episode: 70, Total Reward: 66426968.0\n",
            "Episode: 71, Total Reward: 66696048.0\n",
            "validation_reward: 6525208.0\n",
            "Episode: 72, Total Reward: 62473408.0\n",
            "Episode: 73, Total Reward: 66046728.0\n",
            "Episode: 74, Total Reward: 64013872.0\n",
            "Episode: 75, Total Reward: 67651952.0\n",
            "Episode: 76, Total Reward: 65170600.0\n",
            "validation_reward: 6697440.0\n",
            "Episode: 77, Total Reward: 65194784.0\n",
            "Episode: 78, Total Reward: 62174032.0\n",
            "Episode: 79, Total Reward: 67643024.0\n",
            "Episode: 80, Total Reward: 66449920.0\n",
            "Episode: 81, Total Reward: 69045952.0\n",
            "validation_reward: 8788672.0\n",
            "Episode: 82, Total Reward: 65091560.0\n",
            "Episode: 83, Total Reward: 68417896.0\n",
            "Episode: 84, Total Reward: 70346464.0\n",
            "Episode: 85, Total Reward: 71516440.0\n",
            "Episode: 86, Total Reward: 67556680.0\n",
            "validation_reward: 7563384.0\n",
            "Episode: 87, Total Reward: 71659640.0\n",
            "Episode: 88, Total Reward: 72598424.0\n",
            "Episode: 89, Total Reward: 75406048.0\n",
            "Episode: 90, Total Reward: 60604664.0\n",
            "Episode: 91, Total Reward: 65919696.0\n",
            "validation_reward: 7876288.0\n",
            "Episode: 92, Total Reward: 66958512.0\n",
            "Episode: 93, Total Reward: 67937584.0\n",
            "Episode: 94, Total Reward: 64582584.0\n",
            "Episode: 95, Total Reward: 65590104.0\n",
            "Episode: 96, Total Reward: 64657136.0\n",
            "validation_reward: 6856040.0\n",
            "Episode: 97, Total Reward: 66589144.0\n",
            "Episode: 98, Total Reward: 66323224.0\n",
            "Episode: 99, Total Reward: 65041832.0\n",
            "Episode: 100, Total Reward: 62915744.0\n",
            "Episode: 101, Total Reward: 66556376.0\n",
            "validation_reward: 7226024.0\n",
            "Episode: 102, Total Reward: 65992464.0\n",
            "Episode: 103, Total Reward: 68549200.0\n",
            "Episode: 104, Total Reward: 67701568.0\n",
            "Episode: 105, Total Reward: 68512744.0\n",
            "Episode: 106, Total Reward: 64607264.0\n",
            "validation_reward: 8609680.0\n",
            "Episode: 107, Total Reward: 63611608.0\n",
            "Episode: 108, Total Reward: 67031088.0\n",
            "Episode: 109, Total Reward: 65992160.0\n",
            "Episode: 110, Total Reward: 65184184.0\n",
            "Episode: 111, Total Reward: 65471720.0\n",
            "validation_reward: 7129752.0\n",
            "Episode: 112, Total Reward: 67063600.0\n",
            "Episode: 113, Total Reward: 67529256.0\n",
            "Episode: 114, Total Reward: 67919184.0\n",
            "Episode: 115, Total Reward: 68050360.0\n",
            "Episode: 116, Total Reward: 69339128.0\n",
            "validation_reward: 7894592.0\n",
            "Episode: 117, Total Reward: 67089232.0\n",
            "Episode: 118, Total Reward: 68046712.0\n",
            "Episode: 119, Total Reward: 66380888.0\n",
            "Episode: 120, Total Reward: 69258440.0\n",
            "Episode: 121, Total Reward: 71251960.0\n",
            "validation_reward: 8348408.0\n",
            "Episode: 122, Total Reward: 69633640.0\n",
            "Episode: 123, Total Reward: 70213584.0\n",
            "Episode: 124, Total Reward: 71540968.0\n",
            "Episode: 125, Total Reward: 69517944.0\n",
            "Episode: 126, Total Reward: 71054872.0\n",
            "validation_reward: 7561880.0\n",
            "Episode: 127, Total Reward: 69415000.0\n",
            "Episode: 128, Total Reward: 72363024.0\n",
            "Episode: 129, Total Reward: 70204144.0\n",
            "Episode: 130, Total Reward: 69322480.0\n",
            "Episode: 131, Total Reward: 71742600.0\n",
            "validation_reward: 7426976.0\n",
            "Episode: 132, Total Reward: 73226728.0\n",
            "Episode: 133, Total Reward: 70414072.0\n",
            "Episode: 134, Total Reward: 70338656.0\n",
            "Episode: 135, Total Reward: 74584328.0\n",
            "Episode: 136, Total Reward: 70553600.0\n",
            "validation_reward: 7821088.0\n",
            "Episode: 137, Total Reward: 70919888.0\n",
            "Episode: 138, Total Reward: 71924336.0\n",
            "Episode: 139, Total Reward: 71479896.0\n",
            "Episode: 140, Total Reward: 73209760.0\n",
            "Episode: 141, Total Reward: 70081240.0\n",
            "validation_reward: 7490368.0\n",
            "Episode: 142, Total Reward: 69700456.0\n",
            "Episode: 143, Total Reward: 71533336.0\n",
            "Episode: 144, Total Reward: 70915672.0\n",
            "Episode: 145, Total Reward: 74849688.0\n",
            "Episode: 146, Total Reward: 70956688.0\n",
            "validation_reward: 7607064.0\n",
            "Episode: 147, Total Reward: 70171832.0\n",
            "Episode: 148, Total Reward: 73417704.0\n",
            "Episode: 149, Total Reward: 70910312.0\n",
            "Episode: 150, Total Reward: 72470000.0\n",
            "Episode: 151, Total Reward: 71668976.0\n",
            "validation_reward: 7769552.0\n",
            "Episode: 152, Total Reward: 72248040.0\n",
            "Episode: 153, Total Reward: 74533296.0\n",
            "Episode: 154, Total Reward: 75651368.0\n",
            "Episode: 155, Total Reward: 71579256.0\n",
            "Episode: 156, Total Reward: 75617592.0\n",
            "validation_reward: 8229584.0\n",
            "Episode: 157, Total Reward: 72772808.0\n",
            "Episode: 158, Total Reward: 70955440.0\n",
            "Episode: 159, Total Reward: 71792440.0\n",
            "Episode: 160, Total Reward: 72108024.0\n",
            "Episode: 161, Total Reward: 73835864.0\n",
            "validation_reward: 8253016.0\n",
            "Episode: 162, Total Reward: 75180080.0\n",
            "Episode: 163, Total Reward: 71814520.0\n",
            "Episode: 164, Total Reward: 74529784.0\n",
            "Episode: 165, Total Reward: 71128880.0\n",
            "Episode: 166, Total Reward: 70257968.0\n",
            "validation_reward: 9637776.0\n",
            "Episode: 167, Total Reward: 73984944.0\n",
            "Episode: 168, Total Reward: 74721136.0\n",
            "Episode: 169, Total Reward: 73661152.0\n",
            "Episode: 170, Total Reward: 72986176.0\n",
            "Episode: 171, Total Reward: 71317144.0\n",
            "validation_reward: 8674232.0\n",
            "Episode: 172, Total Reward: 73871744.0\n",
            "Episode: 173, Total Reward: 73359760.0\n",
            "Episode: 174, Total Reward: 71997840.0\n",
            "Episode: 175, Total Reward: 73108272.0\n",
            "Episode: 176, Total Reward: 74354368.0\n",
            "validation_reward: 7739928.0\n",
            "Episode: 177, Total Reward: 71624480.0\n",
            "Episode: 178, Total Reward: 72433904.0\n",
            "Episode: 179, Total Reward: 73541360.0\n",
            "Episode: 180, Total Reward: 73102880.0\n",
            "Episode: 181, Total Reward: 73518760.0\n",
            "validation_reward: 8754640.0\n",
            "Episode: 182, Total Reward: 73799936.0\n",
            "Episode: 183, Total Reward: 72495664.0\n",
            "Episode: 184, Total Reward: 73014240.0\n",
            "Episode: 185, Total Reward: 73522080.0\n",
            "Episode: 186, Total Reward: 73983392.0\n",
            "validation_reward: 8674600.0\n",
            "Episode: 187, Total Reward: 71800488.0\n",
            "Episode: 188, Total Reward: 73514960.0\n",
            "Episode: 189, Total Reward: 73935272.0\n",
            "Episode: 190, Total Reward: 72605144.0\n",
            "Episode: 191, Total Reward: 73290648.0\n",
            "validation_reward: 7352328.0\n",
            "Episode: 192, Total Reward: 74085936.0\n",
            "Episode: 193, Total Reward: 74489424.0\n",
            "Episode: 194, Total Reward: 72166448.0\n",
            "Episode: 195, Total Reward: 73090592.0\n",
            "Episode: 196, Total Reward: 73403432.0\n",
            "validation_reward: 8578152.0\n",
            "Episode: 197, Total Reward: 75413952.0\n",
            "Episode: 198, Total Reward: 72099280.0\n",
            "Episode: 199, Total Reward: 74007456.0\n",
            "Episode: 200, Total Reward: 73191216.0\n",
            "Episode: 201, Total Reward: 73042176.0\n",
            "validation_reward: 7400224.0\n",
            "Episode: 202, Total Reward: 76584416.0\n",
            "Episode: 203, Total Reward: 74156536.0\n",
            "Episode: 204, Total Reward: 71608024.0\n",
            "Episode: 205, Total Reward: 75219872.0\n",
            "Episode: 206, Total Reward: 71438848.0\n",
            "validation_reward: 8149008.0\n",
            "Episode: 207, Total Reward: 72590168.0\n",
            "Episode: 208, Total Reward: 75164736.0\n",
            "Episode: 209, Total Reward: 74840672.0\n",
            "Episode: 210, Total Reward: 72282984.0\n",
            "Episode: 211, Total Reward: 72377216.0\n",
            "validation_reward: 8169952.0\n",
            "Episode: 212, Total Reward: 74735320.0\n",
            "Episode: 213, Total Reward: 74773304.0\n",
            "Episode: 214, Total Reward: 72022968.0\n",
            "Episode: 215, Total Reward: 73553760.0\n",
            "Episode: 216, Total Reward: 73805672.0\n",
            "validation_reward: 9110056.0\n",
            "Episode: 217, Total Reward: 74022856.0\n",
            "Episode: 218, Total Reward: 74742728.0\n",
            "Episode: 219, Total Reward: 73975424.0\n",
            "Episode: 220, Total Reward: 74902936.0\n",
            "Episode: 221, Total Reward: 72176192.0\n",
            "validation_reward: 9099864.0\n",
            "Episode: 222, Total Reward: 74998272.0\n",
            "Episode: 223, Total Reward: 74361848.0\n",
            "Episode: 224, Total Reward: 73625864.0\n",
            "Episode: 225, Total Reward: 76972128.0\n",
            "Episode: 226, Total Reward: 74143872.0\n",
            "validation_reward: 8380304.0\n",
            "Episode: 227, Total Reward: 73957328.0\n",
            "Episode: 228, Total Reward: 72800608.0\n",
            "Episode: 229, Total Reward: 73586136.0\n",
            "Episode: 230, Total Reward: 75580912.0\n",
            "Episode: 231, Total Reward: 73760152.0\n",
            "validation_reward: 8147464.0\n",
            "Episode: 232, Total Reward: 73475936.0\n",
            "Episode: 233, Total Reward: 74301792.0\n",
            "Episode: 234, Total Reward: 74099632.0\n",
            "Episode: 235, Total Reward: 74361864.0\n",
            "Episode: 236, Total Reward: 71074984.0\n",
            "validation_reward: 9262440.0\n",
            "Episode: 237, Total Reward: 73796928.0\n",
            "Episode: 238, Total Reward: 72965704.0\n",
            "Episode: 239, Total Reward: 74664816.0\n",
            "Episode: 240, Total Reward: 74868440.0\n",
            "Episode: 241, Total Reward: 73790680.0\n",
            "validation_reward: 8020448.0\n",
            "Episode: 242, Total Reward: 72543928.0\n",
            "Episode: 243, Total Reward: 74728304.0\n",
            "Episode: 244, Total Reward: 75022200.0\n",
            "Episode: 245, Total Reward: 76044568.0\n",
            "Episode: 246, Total Reward: 75253256.0\n",
            "validation_reward: 8416744.0\n",
            "Episode: 247, Total Reward: 73719672.0\n",
            "Episode: 248, Total Reward: 70657680.0\n",
            "Episode: 249, Total Reward: 73265928.0\n",
            "Episode: 250, Total Reward: 71739408.0\n",
            "Episode: 251, Total Reward: 74286688.0\n",
            "validation_reward: 8703368.0\n",
            "Episode: 252, Total Reward: 73594144.0\n",
            "Episode: 253, Total Reward: 71934904.0\n",
            "Episode: 254, Total Reward: 73476800.0\n",
            "Episode: 255, Total Reward: 73516912.0\n",
            "Episode: 256, Total Reward: 75949184.0\n",
            "validation_reward: 9045136.0\n",
            "Episode: 257, Total Reward: 74552176.0\n",
            "Episode: 258, Total Reward: 75246352.0\n",
            "Episode: 259, Total Reward: 75407376.0\n",
            "Episode: 260, Total Reward: 74758328.0\n",
            "Episode: 261, Total Reward: 73638288.0\n",
            "validation_reward: 7697200.0\n",
            "Episode: 262, Total Reward: 71805048.0\n",
            "Episode: 263, Total Reward: 72869008.0\n",
            "Episode: 264, Total Reward: 71656624.0\n",
            "Episode: 265, Total Reward: 74101768.0\n",
            "Episode: 266, Total Reward: 75489472.0\n",
            "validation_reward: 8713768.0\n",
            "Episode: 267, Total Reward: 73721632.0\n",
            "Episode: 268, Total Reward: 74346328.0\n",
            "Episode: 269, Total Reward: 73580440.0\n",
            "Episode: 270, Total Reward: 72153144.0\n",
            "Episode: 271, Total Reward: 70952464.0\n",
            "validation_reward: 9282240.0\n",
            "Episode: 272, Total Reward: 73609520.0\n",
            "Episode: 273, Total Reward: 73809640.0\n",
            "Episode: 274, Total Reward: 72652728.0\n",
            "Episode: 275, Total Reward: 74256544.0\n",
            "Episode: 276, Total Reward: 73083168.0\n",
            "validation_reward: 8376832.0\n",
            "Episode: 277, Total Reward: 72105912.0\n",
            "Episode: 278, Total Reward: 73194112.0\n",
            "Episode: 279, Total Reward: 74967144.0\n",
            "Episode: 280, Total Reward: 72836856.0\n",
            "Episode: 281, Total Reward: 73312704.0\n",
            "validation_reward: 8918664.0\n",
            "Episode: 282, Total Reward: 73647400.0\n",
            "Episode: 283, Total Reward: 75631368.0\n",
            "Episode: 284, Total Reward: 74463568.0\n",
            "Episode: 285, Total Reward: 73977680.0\n",
            "Episode: 286, Total Reward: 73040672.0\n",
            "validation_reward: 8037184.0\n",
            "Episode: 287, Total Reward: 72801840.0\n",
            "Episode: 288, Total Reward: 74935344.0\n",
            "Episode: 289, Total Reward: 73571112.0\n",
            "Episode: 290, Total Reward: 73453680.0\n",
            "Episode: 291, Total Reward: 74485768.0\n",
            "validation_reward: 8567008.0\n",
            "Episode: 292, Total Reward: 72135328.0\n",
            "Episode: 293, Total Reward: 71279144.0\n",
            "Episode: 294, Total Reward: 72254216.0\n",
            "Episode: 295, Total Reward: 73595512.0\n",
            "Episode: 296, Total Reward: 71708536.0\n",
            "validation_reward: 8469920.0\n",
            "Episode: 297, Total Reward: 73518320.0\n",
            "Episode: 298, Total Reward: 74430624.0\n",
            "Episode: 299, Total Reward: 74574240.0\n",
            "Episode: 300, Total Reward: 73000296.0\n",
            "Episode: 301, Total Reward: 74947840.0\n",
            "validation_reward: 8820712.0\n",
            "Episode: 302, Total Reward: 73979696.0\n",
            "Episode: 303, Total Reward: 74093800.0\n",
            "Episode: 304, Total Reward: 75841104.0\n",
            "Episode: 305, Total Reward: 73420064.0\n",
            "Episode: 306, Total Reward: 74303504.0\n",
            "validation_reward: 7618904.0\n",
            "Episode: 307, Total Reward: 75189760.0\n",
            "Episode: 308, Total Reward: 74178264.0\n",
            "Episode: 309, Total Reward: 72527992.0\n",
            "Episode: 310, Total Reward: 74485112.0\n",
            "Episode: 311, Total Reward: 73465520.0\n",
            "validation_reward: 9110552.0\n",
            "Episode: 312, Total Reward: 73373632.0\n",
            "Episode: 313, Total Reward: 76524448.0\n",
            "Episode: 314, Total Reward: 74043544.0\n",
            "Episode: 315, Total Reward: 71727696.0\n",
            "Episode: 316, Total Reward: 72723104.0\n",
            "validation_reward: 7738832.0\n",
            "Episode: 317, Total Reward: 73581784.0\n",
            "Episode: 318, Total Reward: 73133728.0\n",
            "Episode: 319, Total Reward: 74135616.0\n",
            "Episode: 320, Total Reward: 72905288.0\n",
            "Episode: 321, Total Reward: 72792136.0\n",
            "validation_reward: 7227480.0\n",
            "Episode: 322, Total Reward: 73527040.0\n",
            "Episode: 323, Total Reward: 74351824.0\n",
            "Episode: 324, Total Reward: 70435656.0\n",
            "Episode: 325, Total Reward: 72764096.0\n",
            "Episode: 326, Total Reward: 72495088.0\n",
            "validation_reward: 8380456.0\n",
            "Episode: 327, Total Reward: 73628928.0\n",
            "Episode: 328, Total Reward: 73948104.0\n",
            "Episode: 329, Total Reward: 74453960.0\n",
            "Episode: 330, Total Reward: 70297288.0\n",
            "Episode: 331, Total Reward: 74021920.0\n",
            "validation_reward: 8067288.0\n",
            "Episode: 332, Total Reward: 73041128.0\n",
            "Episode: 333, Total Reward: 73642616.0\n",
            "Episode: 334, Total Reward: 72638648.0\n",
            "Episode: 335, Total Reward: 73461048.0\n",
            "Episode: 336, Total Reward: 77122424.0\n",
            "validation_reward: 8632088.0\n",
            "Episode: 337, Total Reward: 72548752.0\n",
            "Episode: 338, Total Reward: 73952720.0\n",
            "Episode: 339, Total Reward: 74672944.0\n",
            "Episode: 340, Total Reward: 72471280.0\n",
            "Episode: 341, Total Reward: 72731440.0\n",
            "validation_reward: 8128696.0\n",
            "Episode: 342, Total Reward: 73926280.0\n",
            "Episode: 343, Total Reward: 75158512.0\n",
            "Episode: 344, Total Reward: 74591416.0\n",
            "Episode: 345, Total Reward: 73701168.0\n",
            "Episode: 346, Total Reward: 73384200.0\n",
            "validation_reward: 7877288.0\n",
            "Episode: 347, Total Reward: 71743208.0\n",
            "Episode: 348, Total Reward: 73623584.0\n",
            "Episode: 349, Total Reward: 75375624.0\n",
            "Episode: 350, Total Reward: 74957112.0\n",
            "Episode: 351, Total Reward: 73907432.0\n",
            "validation_reward: 7866168.0\n",
            "Episode: 352, Total Reward: 75014536.0\n",
            "Episode: 353, Total Reward: 72293952.0\n",
            "Episode: 354, Total Reward: 70925256.0\n",
            "Episode: 355, Total Reward: 73566432.0\n",
            "Episode: 356, Total Reward: 75406112.0\n",
            "validation_reward: 8959120.0\n",
            "Episode: 357, Total Reward: 73010456.0\n",
            "Episode: 358, Total Reward: 75519592.0\n",
            "Episode: 359, Total Reward: 74289080.0\n",
            "Episode: 360, Total Reward: 74866936.0\n",
            "Episode: 361, Total Reward: 74499832.0\n",
            "validation_reward: 8464272.0\n",
            "Episode: 362, Total Reward: 74715928.0\n",
            "Episode: 363, Total Reward: 74786152.0\n",
            "Episode: 364, Total Reward: 73830616.0\n",
            "Episode: 365, Total Reward: 75628488.0\n",
            "Episode: 366, Total Reward: 72519848.0\n",
            "validation_reward: 8748920.0\n",
            "Episode: 367, Total Reward: 71622936.0\n",
            "Episode: 368, Total Reward: 74014632.0\n",
            "Episode: 369, Total Reward: 72971864.0\n",
            "Episode: 370, Total Reward: 72734752.0\n",
            "Episode: 371, Total Reward: 73989144.0\n",
            "validation_reward: 8954856.0\n",
            "Episode: 372, Total Reward: 71351528.0\n",
            "Episode: 373, Total Reward: 74786208.0\n",
            "Episode: 374, Total Reward: 73705544.0\n",
            "Episode: 375, Total Reward: 74749840.0\n",
            "Episode: 376, Total Reward: 74014360.0\n",
            "validation_reward: 9154184.0\n",
            "Episode: 377, Total Reward: 74069032.0\n",
            "Episode: 378, Total Reward: 74815088.0\n",
            "Episode: 379, Total Reward: 73514416.0\n",
            "Episode: 380, Total Reward: 73088792.0\n",
            "Episode: 381, Total Reward: 74435480.0\n",
            "validation_reward: 8634232.0\n",
            "Episode: 382, Total Reward: 75475336.0\n",
            "Episode: 383, Total Reward: 73274000.0\n",
            "Episode: 384, Total Reward: 74868328.0\n",
            "Episode: 385, Total Reward: 73600616.0\n",
            "Episode: 386, Total Reward: 72909696.0\n",
            "validation_reward: 8449080.0\n",
            "Episode: 387, Total Reward: 73359712.0\n",
            "Episode: 388, Total Reward: 73648656.0\n",
            "Episode: 389, Total Reward: 73801864.0\n",
            "Episode: 390, Total Reward: 70525568.0\n",
            "Episode: 391, Total Reward: 73677264.0\n",
            "validation_reward: 9098104.0\n",
            "Episode: 392, Total Reward: 72553528.0\n",
            "Episode: 393, Total Reward: 75558528.0\n",
            "Episode: 394, Total Reward: 74224808.0\n",
            "Episode: 395, Total Reward: 74595384.0\n",
            "Episode: 396, Total Reward: 74693328.0\n",
            "validation_reward: 8224488.0\n",
            "Episode: 397, Total Reward: 73957464.0\n",
            "Episode: 398, Total Reward: 72671568.0\n",
            "Episode: 399, Total Reward: 73159104.0\n",
            "Episode: 400, Total Reward: 75249576.0\n",
            "Episode: 401, Total Reward: 71669552.0\n",
            "validation_reward: 8948200.0\n",
            "Episode: 402, Total Reward: 73542048.0\n",
            "Episode: 403, Total Reward: 74977864.0\n",
            "Episode: 404, Total Reward: 73598424.0\n",
            "Episode: 405, Total Reward: 73084096.0\n",
            "Episode: 406, Total Reward: 72948312.0\n",
            "validation_reward: 8835760.0\n",
            "Episode: 407, Total Reward: 74215280.0\n",
            "Episode: 408, Total Reward: 74723720.0\n",
            "Episode: 409, Total Reward: 73770344.0\n",
            "Episode: 410, Total Reward: 74473440.0\n",
            "Episode: 411, Total Reward: 75569848.0\n",
            "validation_reward: 8522424.0\n",
            "Episode: 412, Total Reward: 74540288.0\n",
            "Episode: 413, Total Reward: 73501392.0\n",
            "Episode: 414, Total Reward: 75205696.0\n",
            "Episode: 415, Total Reward: 73644448.0\n",
            "Episode: 416, Total Reward: 72285512.0\n",
            "validation_reward: 8470256.0\n",
            "Episode: 417, Total Reward: 75220080.0\n",
            "Episode: 418, Total Reward: 72237488.0\n",
            "Episode: 419, Total Reward: 74342744.0\n",
            "Episode: 420, Total Reward: 72707344.0\n",
            "Episode: 421, Total Reward: 73217680.0\n",
            "validation_reward: 9105008.0\n",
            "Episode: 422, Total Reward: 75077304.0\n",
            "Episode: 423, Total Reward: 73648968.0\n",
            "Episode: 424, Total Reward: 73125456.0\n",
            "Episode: 425, Total Reward: 73600448.0\n",
            "Episode: 426, Total Reward: 74936912.0\n",
            "validation_reward: 9471912.0\n",
            "Episode: 427, Total Reward: 73046968.0\n",
            "Episode: 428, Total Reward: 72860656.0\n",
            "Episode: 429, Total Reward: 72011200.0\n",
            "Episode: 430, Total Reward: 73248120.0\n",
            "Episode: 431, Total Reward: 72142736.0\n",
            "validation_reward: 8538408.0\n",
            "Episode: 432, Total Reward: 73341240.0\n",
            "Episode: 433, Total Reward: 75313688.0\n",
            "Episode: 434, Total Reward: 73946840.0\n",
            "Episode: 435, Total Reward: 72398264.0\n",
            "Episode: 436, Total Reward: 74182688.0\n",
            "validation_reward: 9057544.0\n",
            "Episode: 437, Total Reward: 75295792.0\n",
            "Episode: 438, Total Reward: 73929656.0\n",
            "Episode: 439, Total Reward: 74584816.0\n",
            "Episode: 440, Total Reward: 71789096.0\n",
            "Episode: 441, Total Reward: 75120312.0\n",
            "validation_reward: 8838936.0\n",
            "Episode: 442, Total Reward: 74107384.0\n",
            "Episode: 443, Total Reward: 75259960.0\n",
            "Episode: 444, Total Reward: 72907592.0\n",
            "Episode: 445, Total Reward: 73563256.0\n",
            "Episode: 446, Total Reward: 74271680.0\n",
            "validation_reward: 8146592.0\n",
            "Episode: 447, Total Reward: 73624376.0\n",
            "Episode: 448, Total Reward: 72968296.0\n",
            "Episode: 449, Total Reward: 74202384.0\n",
            "Episode: 450, Total Reward: 72098576.0\n",
            "Episode: 451, Total Reward: 72841976.0\n",
            "validation_reward: 8579456.0\n",
            "Episode: 452, Total Reward: 74201728.0\n",
            "Episode: 453, Total Reward: 72994632.0\n",
            "Episode: 454, Total Reward: 74085968.0\n",
            "Episode: 455, Total Reward: 74993256.0\n",
            "Episode: 456, Total Reward: 73067072.0\n",
            "validation_reward: 7784760.0\n",
            "Episode: 457, Total Reward: 74637216.0\n",
            "Episode: 458, Total Reward: 74010888.0\n",
            "Episode: 459, Total Reward: 74657280.0\n",
            "Episode: 460, Total Reward: 74264320.0\n",
            "Episode: 461, Total Reward: 71714576.0\n",
            "validation_reward: 9262296.0\n",
            "Episode: 462, Total Reward: 73632736.0\n",
            "Episode: 463, Total Reward: 76517592.0\n",
            "Episode: 464, Total Reward: 75039016.0\n",
            "Episode: 465, Total Reward: 73935848.0\n",
            "Episode: 466, Total Reward: 73192072.0\n",
            "validation_reward: 8752184.0\n",
            "Episode: 467, Total Reward: 75363624.0\n",
            "Episode: 468, Total Reward: 75424392.0\n",
            "Episode: 469, Total Reward: 75555096.0\n",
            "Episode: 470, Total Reward: 76822368.0\n",
            "Episode: 471, Total Reward: 74489680.0\n",
            "validation_reward: 8896056.0\n",
            "Episode: 472, Total Reward: 73145184.0\n",
            "Episode: 473, Total Reward: 74922432.0\n",
            "Episode: 474, Total Reward: 75925688.0\n",
            "Episode: 475, Total Reward: 73901088.0\n",
            "Episode: 476, Total Reward: 70131472.0\n",
            "validation_reward: 8868968.0\n",
            "Episode: 477, Total Reward: 74797896.0\n",
            "Episode: 478, Total Reward: 72276560.0\n",
            "Episode: 479, Total Reward: 76532816.0\n",
            "Episode: 480, Total Reward: 73819224.0\n",
            "Episode: 481, Total Reward: 74224592.0\n",
            "validation_reward: 8841200.0\n",
            "Episode: 482, Total Reward: 73737376.0\n",
            "Episode: 483, Total Reward: 73828216.0\n",
            "Episode: 484, Total Reward: 74609176.0\n",
            "Episode: 485, Total Reward: 74175216.0\n",
            "Episode: 486, Total Reward: 74878664.0\n",
            "validation_reward: 9783664.0\n",
            "Episode: 487, Total Reward: 72412048.0\n",
            "Episode: 488, Total Reward: 75025248.0\n",
            "Episode: 489, Total Reward: 73421400.0\n",
            "Episode: 490, Total Reward: 74311584.0\n",
            "Episode: 491, Total Reward: 75890456.0\n",
            "validation_reward: 8492544.0\n",
            "Episode: 492, Total Reward: 75858296.0\n",
            "Episode: 493, Total Reward: 71507120.0\n",
            "Episode: 494, Total Reward: 73116872.0\n",
            "Episode: 495, Total Reward: 75748392.0\n",
            "Episode: 496, Total Reward: 75664864.0\n",
            "validation_reward: 9445200.0\n",
            "Episode: 497, Total Reward: 73785688.0\n",
            "Episode: 498, Total Reward: 72167384.0\n",
            "Episode: 499, Total Reward: 72148248.0\n",
            "Episode: 500, Total Reward: 75462008.0\n"
          ]
        }
      ],
      "source": [
        "EPISODE = 500\n",
        "Env = env(merged_data_all)\n",
        "Agent =  A2CAgent(window_size = 30, num_stocks = 3, feature_len = 128, n_channels=16, k=K)\n",
        "\n",
        "for episode in range(EPISODE):\n",
        "    state = Env.train_reset()\n",
        "    total_reward = torch.tensor(0, device = device, dtype = torch.float32)\n",
        "    for i in range(Env.train_data.shape[0]-2):\n",
        "        #print(i)\n",
        "        action = Agent.act(state.to(device))\n",
        "        next_state, reward, done = Env.train_step(state, action)\n",
        "        #print(torch.stack(list(Agent.state_buffer)).shape)\n",
        "        if torch.stack(list(Agent.state_buffer)).shape[0] == 30:\n",
        "            Agent.remember(torch.stack(list(Agent.state_buffer)), action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        if i % 500 == 0:\n",
        "            Agent.replay()\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "\n",
        "    if episode % 1 == 0:\n",
        "        print(f\"Episode: {episode + 1}, Total Reward: {total_reward}\")\n",
        "\n",
        "    if episode % 5 == 0:\n",
        "        Env = env(merged_data_all)\n",
        "        state = Env.valid_reset()\n",
        "        valid_reward = torch.tensor(0, device = device, dtype = torch.float32)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(Env.test_data.shape[0]-2):\n",
        "                action = Agent.act(state.to(device))\n",
        "                next_state, reward, done = Env.test_step(state, action)\n",
        "                state = next_state\n",
        "                valid_reward += reward\n",
        "\n",
        "        print(\"validation_reward:\",valid_reward.item())\n",
        "\n",
        "\n",
        "#torch.save(Agent.model.state_dict(), f'DQN_epoch{EPISODE}trained_model_weights.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A2C Test"
      ],
      "metadata": {
        "id": "XnbWF32RUeGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트는 트레이닝시와 동일하게 1억원의 잔고를 가지고 진행\n",
        "초기값에 큰 영향을 받아서 낮으면 1%에서 높으면 11% 정도의 수익을 올렸습니다"
      ],
      "metadata": {
        "id": "oeDzKgVKpMv5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gEXmVLRvlov",
        "outputId": "1600d493-4566-42fe-afaf-9dfab60e8890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total_reward: tensor(11387168.)\n"
          ]
        }
      ],
      "source": [
        "Env = env(merged_data_all)\n",
        "state = Env.test_reset()\n",
        "total_reward = torch.tensor(0, device = device, dtype = torch.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(Env.test_data.shape[0]-2):\n",
        "        action = Agent.act(state.to(device))\n",
        "        next_state, reward, done = Env.test_step(state, action)\n",
        "        #print(f\"{i}th reward:{reward}\")\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "print(\"total_reward:\",total_reward)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zovwAyYqvdRh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}